{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "#This script is implemented using Jupyter notebook. \n",
    "#Therefore, to draw graphs within the notebook, we have used the command %matplotlib inline. If you are using Spyder, you can remove the last line.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "petrol_data = pd.read_csv(\"~/Desktop/Datasets/petrol_data.csv\")\n",
    "#this script reads the dataset and stores it in petrol_datadataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Petrol_tax  Average_income  Paved_Highways  Population_Driver_licence(%)  \\\n0         9.0            3571            1976                         0.525   \n1         9.0            4092            1250                         0.572   \n2         9.0            3865            1586                         0.580   \n3         7.5            4870            2351                         0.529   \n4         8.0            4399             431                         0.544   \n\n   Petrol_Consumption  \n0                 541  \n1                 524  \n2                 561  \n3                 414  \n4                 410  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Petrol_tax</th>\n      <th>Average_income</th>\n      <th>Paved_Highways</th>\n      <th>Population_Driver_licence(%)</th>\n      <th>Petrol_Consumption</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9.0</td>\n      <td>3571</td>\n      <td>1976</td>\n      <td>0.525</td>\n      <td>541</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9.0</td>\n      <td>4092</td>\n      <td>1250</td>\n      <td>0.572</td>\n      <td>524</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9.0</td>\n      <td>3865</td>\n      <td>1586</td>\n      <td>0.580</td>\n      <td>561</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7.5</td>\n      <td>4870</td>\n      <td>2351</td>\n      <td>0.529</td>\n      <td>414</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8.0</td>\n      <td>4399</td>\n      <td>431</td>\n      <td>0.544</td>\n      <td>410</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "petrol_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following script divides the data into feature and label set. \n",
    "features = petrol_data.iloc[:,0:4].values\n",
    "labels =petrol_data.iloc[:,4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The next thing is to divide the data into 80% training and 20% test sets:\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_features,test_features,train_labels,test_labels = train_test_split(features,labels,test_size = 0.2,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you look at the dataset you can see that it is not scaled properly.The feature Population_Driver_License has values between\n",
    "#0 and 1 while Average_Income and Paved_Highways has values in thousands.\n",
    "#Before feeding our data to the algorithm, we need to scale our features.\n",
    "#To do that we run the following script\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "feature_scaler = StandardScaler()\n",
    "train_features_poly = feature_scaler.fit_transform(train_features)\n",
    "test_features_poly = feature_scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.32525691e-01,  1.50577399e+00,  2.25854636e+00,\n",
       "        -9.15791057e-01],\n",
       "       [-6.28192647e-01, -1.83367022e+00,  2.12333843e-01,\n",
       "        -1.12852703e+00],\n",
       "       [-1.32525691e-01, -1.78897047e+00, -4.54194551e-01,\n",
       "        -5.25775100e-01],\n",
       "       [-1.32525691e-01, -8.78212954e-01,  8.77245103e-01,\n",
       "         4.15208375e-02],\n",
       "       [-6.28192647e-01,  1.27482526e+00,  1.07480487e+00,\n",
       "         2.89712810e-01],\n",
       "       [ 1.35447518e+00, -8.42825648e-01, -1.13743332e+00,\n",
       "         5.92488356e-02],\n",
       "       [-6.28192647e-01, -4.00925436e-02, -4.64436395e-01,\n",
       "         8.21552752e-01],\n",
       "       [-6.28192647e-01,  7.42153173e-01,  2.93282707e-02,\n",
       "         2.61208055e+00],\n",
       "       [-6.28192647e-01,  8.82232011e-04,  1.22196399e+00,\n",
       "         1.65616824e-01],\n",
       "       [ 3.63141265e-01, -2.41241442e-01,  4.54996025e-02,\n",
       "        -2.42127131e-01],\n",
       "       [ 1.35447518e+00,  1.07926383e+00, -9.04835665e-01,\n",
       "        -1.16398303e+00],\n",
       "       [-6.28192647e-01, -2.07716626e-01,  7.28199328e-01,\n",
       "        -8.25751488e-02],\n",
       "       [-6.28192647e-01, -1.23208602e+00, -4.90849570e-01,\n",
       "        -2.42127131e-01],\n",
       "       [-6.28192647e-01,  5.13066928e-01,  5.46541367e-01,\n",
       "         1.53067267e+00],\n",
       "       [-6.28192647e-01, -3.26425844e-02, -5.85182339e-01,\n",
       "         4.66992791e-01],\n",
       "       [ 3.63141265e-01,  2.41143416e-01,  7.46796360e-01,\n",
       "        -8.44879065e-01],\n",
       "       [-6.28192647e-01, -2.05854136e-01,  2.08560532e-01,\n",
       "        -5.61231096e-01],\n",
       "       [ 1.35447518e+00, -1.11102418e+00, -2.85743178e-01,\n",
       "        -5.78959094e-01],\n",
       "       [ 2.34580909e+00,  1.90807179e+00, -1.20562244e+00,\n",
       "        -1.00303147e-01],\n",
       "       [-6.28192647e-01, -1.11661165e+00, -2.91403144e-01,\n",
       "        -6.49871086e-01],\n",
       "       [-1.04455289e+00, -9.60162506e-01,  5.46541367e-01,\n",
       "         9.27920740e-01],\n",
       "       [-6.28192647e-01,  2.69570892e-02,  6.34136081e-01,\n",
       "         5.55632781e-01],\n",
       "       [ 8.58808221e-01, -1.27119830e+00, -6.82479852e-01,\n",
       "         1.53067267e+00],\n",
       "       [ 1.35447518e+00, -4.20040463e-01, -1.22799278e+00,\n",
       "        -8.25751488e-02],\n",
       "       [-6.28192647e-01,  9.30264643e-01,  3.02893301e-01,\n",
       "        -4.71191527e-02],\n",
       "       [-6.28192647e-01, -1.06632442e+00, -8.61173069e-01,\n",
       "        -1.21716702e+00],\n",
       "       [ 8.58808221e-01,  4.77679621e-01, -8.59016891e-01,\n",
       "        -4.54863108e-01],\n",
       "       [ 3.63141265e-01,  1.86523452e+00,  1.63379391e+00,\n",
       "        -2.22766291e+00],\n",
       "       [ 1.35447518e+00, -1.10867156e-01, -3.01914510e-01,\n",
       "        -1.05761504e+00],\n",
       "       [-2.61086047e+00, -5.07577484e-01,  3.22774818e+00,\n",
       "        -1.88943137e-01],\n",
       "       [ 3.63141265e-01,  1.23943795e+00, -1.40264316e+00,\n",
       "         4.49264793e-01],\n",
       "       [ 8.58808221e-01,  4.37194975e-02,  5.49328794e-02,\n",
       "         1.77886465e+00],\n",
       "       [-6.28192647e-01,  3.62205254e-01,  7.27929806e-01,\n",
       "        -4.37135110e-01],\n",
       "       [-6.28192647e-01,  5.11694567e-02, -5.12411346e-01,\n",
       "         1.69022466e+00],\n",
       "       [ 1.35447518e+00,  2.95155621e-01, -5.02439024e-01,\n",
       "        -1.00303147e-01],\n",
       "       [-1.32525691e-01,  1.02897660e+00, -9.31248840e-01,\n",
       "        -8.44879065e-01],\n",
       "       [ 1.35447518e+00, -1.39039765e+00, -1.03231966e+00,\n",
       "        -9.15791057e-01],\n",
       "       [-1.61952656e+00,  1.67153558e+00, -9.44455428e-01,\n",
       "         1.69022466e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[ 1.35447518, -1.33452296, -0.31161731, -1.48308699],\n       [ 0.36314126,  0.15174391, -1.44873146, -0.57895909],\n       [ 0.36314126, -1.6194839 , -0.10974518, -0.5080471 ],\n       [-0.62819265, -1.26188585,  0.29615525, -1.03988704],\n       [ 0.36314126, -2.33654247,  0.19346729,  0.02379284],\n       [-0.62819265, -0.78322597,  0.1560037 ,  0.16561682],\n       [ 0.36314126, -1.47048471, -0.62291545, -1.58945498],\n       [-0.62819265,  0.2448684 , -0.31458205,  0.87473675],\n       [ 0.36314126,  1.50577399, -0.98865707, -0.41940711],\n       [ 0.36314126,  0.13684399,  0.0357968 , -0.82715107]])"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "test_features_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n            max_features=None, max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n            splitter='best')"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "#We have scaled our features down, now it is time to train the algorithm. \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_reg = DecisionTreeClassifier()\n",
    "dt_reg.fit(train_features,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dt_reg.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([591, 540, 574, 547, 574, 508, 591, 968, 460, 464])"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison=pd.DataFrame({'Predictions':predictions, 'Real':test_labels, })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Predictions  Real\n0          591   534\n1          540   410\n2          574   577\n3          547   571\n4          574   577\n5          508   704\n6          591   487\n7          968   587\n8          460   467\n9          464   580\n"
    }
   ],
   "source": [
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([534, 410, 577, 571, 577, 704, 487, 587, 467, 580])"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MAE: 102.1\nMSE: 22864.1\nRMSE: 151.20879604044202\n"
    }
   ],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(test_labels, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(test_labels, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(test_labels, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The value of MAE is 79, which is greater than MAE value calculated for Polynomial Regression algorithm in the last chapter. Similarly, the value of RMSE in the case of decision tree is 118 which\n",
    "#MAE:84.2\n",
    "#MSE:18823.4\n",
    "#RMSE: 137.19"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('base': conda)",
   "language": "python",
   "name": "python37164bitbasecondadd8648a7cdd747a584bf28b8b6a8b143"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}